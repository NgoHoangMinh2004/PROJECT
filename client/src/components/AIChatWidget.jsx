import React, { useState, useRef, useEffect } from 'react';
import { Input, Card, message, Tooltip, Popconfirm } from 'antd';
import { CloseOutlined, DeleteOutlined, AudioOutlined, LoadingOutlined, RobotOutlined } from '@ant-design/icons';
import axiosClient from '../services/axiosClient';

const AIChatWidget = () => {
    // --- STATE ---
    const [visible, setVisible] = useState(false);
    const [messages, setMessages] = useState(() => {
        try {
            const saved = localStorage.getItem('hm_chat_history');
            return saved ? JSON.parse(saved) : [{ role: 'ai', content: 'Ch√†o b·∫°n! M√¨nh l√† Minh.' }];
        } catch { return []; }
    });
    const [inputValue, setInputValue] = useState('');

    // UI STATES
    const [isListening, setIsListening] = useState(false);
    const [isThinking, setIsThinking] = useState(false);
    const [conversationMode, setConversationMode] = useState(false);

    // REFS (Qu·∫£n l√Ω logic ng·∫ßm)
    const recognitionRef = useRef(null);
    const silenceTimerRef = useRef(null);
    const messagesEndRef = useRef(null);
    const textBufferRef = useRef('');
    const isSendingRef = useRef(false);

    // [QUAN TR·ªåNG] Ref ƒë·ªÉ gi·ªØ gi√° tr·ªã State lu√¥n m·ªõi nh·∫•t trong c√°c h√†m Callback
    const conversationModeRef = useRef(false);
    const utteranceRef = useRef(null); // Gi·ªØ gi·ªçng ƒë·ªçc kh√¥ng b·ªã Chrome x√≥a

    const characterImage = "https://cdn-icons-png.flaticon.com/512/4712/4712035.png";

    // Update Ref khi State ƒë·ªïi
    useEffect(() => { conversationModeRef.current = conversationMode; }, [conversationMode]);

    // Auto scroll
    useEffect(() => {
        messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
        localStorage.setItem('hm_chat_history', JSON.stringify(messages));
    }, [messages, visible]);

    // --- TTS (ƒê·ªåC) - PHI√äN B·∫¢N CH·ªêNG L·ªñI ---
    const speak = (text, onFinished) => {
        if (!text) { if (onFinished) onFinished(); return; }

        // H·ªßy c√°c gi·ªçng ƒë·ªçc c≈© ƒëang treo
        window.speechSynthesis.cancel();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'vi-VN';
        utterance.rate = 1.1;

        // [FIX L·ªñI CHROME]: G√°n v√†o Ref ƒë·ªÉ kh√¥ng b·ªã Garbage Collection x√≥a
        utteranceRef.current = utterance;

        utterance.onend = () => {
            console.log("üó£Ô∏è ƒê√£ ƒë·ªçc xong.");
            if (onFinished) onFinished();
        };

        utterance.onerror = (e) => {
            console.error("L·ªói ƒë·ªçc:", e);
            if (onFinished) onFinished();
        };

        window.speechSynthesis.speak(utterance);
    };

    // --- MICROPHONE ENGINE ---
    const startListening = () => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) return;

        // N·∫øu Mic ƒë√£ c√≥ v√† ƒëang ch·∫°y (state kh√¥ng ph·∫£i ƒë√£ t·∫Øt), th√¨ kh√¥ng start l·∫°i
        // Tuy nhi√™n ·ªü ƒë√¢y ta d√πng recognitionRef ƒë·ªÉ check instance
        if (recognitionRef.current) {
            try { recognitionRef.current.abort(); } catch (e) { }
        }

        const recognition = new SpeechRecognition();
        recognition.lang = 'vi-VN';
        recognition.continuous = true;
        recognition.interimResults = true;

        recognition.onstart = () => {
            console.log("üéôÔ∏è Mic ƒê√É B·∫¨T - S·∫µn s√†ng nghe");
            setIsListening(true);
        };

        recognition.onend = () => {
            console.log("‚èπÔ∏è Mic ƒê√É T·∫ÆT");
            setIsListening(false);
            recognitionRef.current = null;

            // LOGIC T·ª∞ ƒê·ªòNG B·∫¨T L·∫†I (Auto-Resume)
            // Ch·ªâ b·∫≠t l·∫°i n·∫øu:
            // 1. ƒêang ·ªü ch·∫ø ƒë·ªô h·ªôi tho·∫°i (conversationModeRef.current = true)
            // 2. Kh√¥ng ph·∫£i ƒëang g·ª≠i tin nh·∫Øn (isSendingRef.current = false)
            // 3. AI kh√¥ng ƒëang suy nghƒ© (isThinking = false)
            if (conversationModeRef.current && !isSendingRef.current && !isThinking) {
                console.log("üîÑ Mic t·∫Øt b·∫•t ng·ªù -> T·ª± ƒë·ªông b·∫≠t l·∫°i sau 0.5s...");
                setTimeout(startListening, 500);
            }
        };

        recognition.onresult = (event) => {
            const resultIndex = event.resultIndex;
            const transcript = event.results[resultIndex][0].transcript.toLowerCase().trim();
            const isFinal = event.results[resultIndex].isFinal;

            setInputValue(transcript);
            textBufferRef.current = transcript;

            // --- LOGIC 1.2 GI√ÇY IM L·∫∂NG ---
            if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);

            silenceTimerRef.current = setTimeout(() => {
                // Ch·ªâ g·ª≠i n·∫øu c√≥ n·ªôi dung
                if (textBufferRef.current.length > 0 && !isSendingRef.current) {
                    console.log("‚è≥ H·∫øt 1.2s -> Ch·ªët ƒë∆°n:", textBufferRef.current);

                    isSendingRef.current = true; // Kh√≥a g·ª≠i

                    // D·ª´ng Mic th·ªß c√¥ng ƒë·ªÉ tr√°nh thu t·∫°p √¢m l√∫c AI ƒëang x·ª≠ l√Ω
                    if (recognitionRef.current) recognitionRef.current.stop();

                    handleSend(textBufferRef.current);
                }
            }, 1200);
        };

        try {
            recognition.start();
            recognitionRef.current = recognition;
        } catch (e) {
            console.error("L·ªói b·∫≠t Mic:", e);
        }
    };

    const stopListening = () => {
        if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);
        if (recognitionRef.current) recognitionRef.current.abort();
        recognitionRef.current = null;
        setIsListening(false);
    };

    // --- SEND LOGIC ---
    const handleSend = async (text) => {
        if (!text.trim()) return;

        setIsThinking(true);
        setInputValue('');
        textBufferRef.current = '';

        // UI User
        setMessages(prev => [...prev, { role: 'user', content: text }]);

        try {
            const historyToSend = messages.slice(-10);
            // G·ª≠i request l√™n server
            const res = await axiosClient.post('/ai/chat', { message: text, history: historyToSend });

            const reply = res.reply || "Minh ch∆∞a nghƒ© ra c√¢u tr·∫£ l·ªùi.";
            setMessages(prev => [...prev, { role: 'ai', content: reply }]);

            speak(reply, () => {
                isSendingRef.current = false;
                setIsThinking(false);
                if (conversationModeRef.current) startListening();
            });

        } catch (error) {
            let errorMsg = "L·ªói k·∫øt n·ªëi Server.";

            // Ki·ªÉm tra n·∫øu l√† l·ªói 429 (H·∫øt l∆∞·ª£t) t·ª´ Backend g·ª≠i v·ªÅ
            if (error.response && error.response.status === 429) {
                // L·∫•y c√¢u th√¥ng b√°o "Hic, Minh n√≥i chuy·ªán nhi·ªÅu qu√°..." t·ª´ Backend
                errorMsg = error.response.data.reply || "Server ƒëang qu√° t·∫£i, th·ª≠ l·∫°i sau nh√©!";
            } else if (error.response && error.response.data && error.response.data.reply) {
                // C√°c l·ªói kh√°c c√≥ tin nh·∫Øn t·ª´ server (v√≠ d·ª• l·ªói 500 do sai model)
                errorMsg = error.response.data.reply;
            }

            // Hi·ªán tin nh·∫Øn l·ªói v√†o khung chat nh∆∞ m·ªôt l·ªùi tho·∫°i c·ªßa AI
            setMessages(prev => [...prev, { role: 'ai', content: errorMsg }]);

            speak(errorMsg, () => {
                isSendingRef.current = false;
                setIsThinking(false);
                // V·∫´n cho ph√©p b·∫≠t l·∫°i mic ƒë·ªÉ ng∆∞·ªùi d√πng th·ª≠ l·∫°i sau
                if (conversationModeRef.current) startListening();
            });
        }
    };

    // --- TOGGLE CH·∫æ ƒê·ªò R·∫¢NH TAY ---
    const toggleConversation = () => {
        if (conversationMode) {
            // T·∫ÆT
            setConversationMode(false); // Ref s·∫Ω t·ª± update qua useEffect
            stopListening();
            window.speechSynthesis.cancel();
            message.info("ƒê√£ t·∫Øt ch·∫ø ƒë·ªô r·∫£nh tay.");
        } else {
            // B·∫¨T
            setConversationMode(true);
            // setConversationMode l√† b·∫•t ƒë·ªìng b·ªô, n√™n ta d√πng bi·∫øn t·∫°m ho·∫∑c Ref n·∫øu c·∫ßn logic ngay
            conversationModeRef.current = true;

            const greeting = "B·∫Øt ƒë·∫ßu h·ªôi tho·∫°i. B·∫°n n√≥i ƒëi...";
            speak(greeting, () => {
                startListening();
            });
            message.success("Ch·∫ø ƒë·ªô r·∫£nh tay ƒë√£ b·∫≠t!");
        }
    };

    const clearHistory = () => {
        setMessages([{ role: 'ai', content: 'Ch√†o b·∫°n! M√¨nh l√† Ming.' }]);
        localStorage.removeItem('hm_chat_history');
        message.success("ƒê√£ l√†m m·ªõi.");
    };

    return (
        <div style={{ position: 'fixed', bottom: 20, right: 20, zIndex: 9999, display: 'flex', flexDirection: 'column', alignItems: 'flex-end' }}>

            {visible && (
                <Card
                    title={
                        <div style={{ color: '#fff', display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
                            <span style={{ fontWeight: 'bold' }}>ü§ñ Tr·ª£ l√Ω Ming</span>
                            <CloseOutlined onClick={() => { setVisible(false); setConversationMode(false); stopListening(); }} style={{ color: '#fff', cursor: 'pointer' }} />
                        </div>
                    }
                    styles={{ body: { padding: 0, display: 'flex', flexDirection: 'column', height: 400 }, header: { background: '#58cc02', padding: '0 15px' } }}
                    style={{ width: 340, marginBottom: 15, borderRadius: 15, border: 'none', boxShadow: '0 10px 30px rgba(0,0,0,0.2)' }}
                >
                    <div style={{ flex: 1, padding: '15px', overflowY: 'auto', background: '#f5f5f5' }}>
                        {messages.map((item, index) => (
                            <div key={index} style={{ display: 'flex', justifyContent: item.role === 'user' ? 'flex-end' : 'flex-start', marginBottom: 10 }}>
                                {item.role === 'ai' && <img src={characterImage} alt="AI" style={{ width: 28, height: 28, marginRight: 8, borderRadius: '50%' }} />}
                                <div style={{
                                    maxWidth: '80%', padding: '10px 14px', borderRadius: '15px',
                                    background: item.role === 'user' ? '#58cc02' : '#fff',
                                    color: item.role === 'user' ? '#fff' : '#333',
                                    boxShadow: '0 2px 5px rgba(0,0,0,0.05)'
                                }}>
                                    {item.content}
                                </div>
                            </div>
                        ))}

                        {/* TR·∫†NG TH√ÅI MIC REAL-TIME */}
                        {isListening && (
                            <div style={{ color: '#58cc02', fontStyle: 'italic', fontSize: 12, padding: 10, textAlign: 'right' }}>
                                üéôÔ∏è {inputValue || "ƒêang l·∫Øng nghe..."}
                            </div>
                        )}
                        {isThinking && <div style={{ padding: 10, fontSize: 12, color: '#888' }}>M√¨nh ƒëang suy nghƒ©, b·∫°n ƒë·ª£i 1 x√≠u nh√©...</div>}
                        <div ref={messagesEndRef} />
                    </div>

                    <div style={{ padding: 10, background: '#fff', display: 'flex', gap: 5, borderTop: '1px solid #eee' }}>
                        <Input
                            value={inputValue}
                            onChange={(e) => setInputValue(e.target.value)}
                            placeholder={isListening ? "ƒêang nghe b·∫°n n√≥i..." : "Nh·∫≠p tin nh·∫Øn..."}
                            disabled={isListening}
                            onPressEnter={() => handleSend(inputValue)}
                            style={{ borderRadius: 20 }}
                        />

                        {/* N√öT MIC TH·∫¶N TH√ÅNH */}
                        <div
                            onClick={toggleConversation}
                            style={{
                                cursor: 'pointer', width: 40, height: 32, borderRadius: '20px',
                                display: 'flex', alignItems: 'center', justifyContent: 'center',
                                background: conversationMode ? '#ff4d4f' : '#f0f0f0',
                                color: conversationMode ? '#fff' : '#666',
                                transition: 'all 0.3s',
                                boxShadow: conversationMode ? '0 0 10px rgba(255, 77, 79, 0.5)' : 'none'
                            }}
                        >
                            {isThinking ? <LoadingOutlined /> : <AudioOutlined spin={isListening} />}
                        </div>
                    </div>
                </Card>
            )}

            {/* AVATAR TRIGGER */}
            <div onClick={() => setVisible(!visible)} className="ai-avatar-trigger" style={{ cursor: 'pointer' }}>
                <img src={characterImage} alt="AI" style={{ width: 70, height: 70, filter: 'drop-shadow(0 4px 8px rgba(0,0,0,0.2))' }} />
            </div>
        </div>
    );
};

export default AIChatWidget;